# API æ–‡æ¡£

LiteFlow æ”¯æŒå¤šç§ LLM æœåŠ¡æä¾›å•†çš„ APIã€‚æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜äº†å¦‚ä½•é…ç½®å’Œä½¿ç”¨ä¸åŒçš„ APIã€‚

## ğŸ”§ æ”¯æŒçš„ API æ ¼å¼

LiteFlow ä½¿ç”¨æ ‡å‡†çš„ OpenAI API æ ¼å¼ï¼Œå…¼å®¹å¤§å¤šæ•° LLM æœåŠ¡æä¾›å•†ã€‚

### åŸºæœ¬è¯·æ±‚æ ¼å¼

```javascript
POST {baseUrl}/chat/completions
Content-Type: application/json
Authorization: Bearer {apiKey}

{
  "model": "{modelName}",
  "messages": [
    {
      "role": "user",
      "content": "ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬"
    }
  ],
  "temperature": 0.7
}
```

### å“åº”æ ¼å¼

```javascript
{
  "choices": [
    {
      "message": {
        "content": "AI ç”Ÿæˆçš„å›å¤"
      }
    }
  ]
}
```

## ğŸŒ æ”¯æŒçš„æœåŠ¡æä¾›å•†

### 1. OpenAI

**é…ç½®ç¤ºä¾‹:**
- Base URL: `https://api.openai.com/v1`
- API Key: `sk-...`
- Model Name: `gpt-3.5-turbo`, `gpt-4`, `gpt-4-turbo`

**ç‰¹ç‚¹:**
- æœ€ç¨³å®šçš„æœåŠ¡
- æ”¯æŒå¤šç§æ¨¡å‹
- å“åº”é€Ÿåº¦å¿«

**è·å– API Key:**
1. è®¿é—® [OpenAI Platform](https://platform.openai.com/)
2. æ³¨å†Œè´¦æˆ·å¹¶éªŒè¯
3. åœ¨ API Keys é¡µé¢åˆ›å»ºæ–°çš„ API Key

### 2. Groq

**é…ç½®ç¤ºä¾‹:**
- Base URL: `https://api.groq.com/openai/v1`
- API Key: `gsk_...`
- Model Name: `llama2-70b-4096`, `mixtral-8x7b-32768`

**ç‰¹ç‚¹:**
- æå¿«çš„æ¨ç†é€Ÿåº¦
- å…è´¹é¢åº¦è¾ƒé«˜
- æ”¯æŒå¼€æºæ¨¡å‹

**è·å– API Key:**
1. è®¿é—® [Groq Console](https://console.groq.com/)
2. æ³¨å†Œè´¦æˆ·
3. åœ¨ API Keys é¡µé¢åˆ›å»º API Key

### 3. Together AI

**é…ç½®ç¤ºä¾‹:**
- Base URL: `https://api.together.xyz/v1`
- API Key: `...`
- Model Name: `meta-llama/Llama-2-70b-chat-hf`, `mistralai/Mixtral-8x7B-Instruct-v0.1`

**ç‰¹ç‚¹:**
- æ”¯æŒå¤šç§å¼€æºæ¨¡å‹
- ä»·æ ¼ç›¸å¯¹ä¾¿å®œ
- æ¨¡å‹é€‰æ‹©ä¸°å¯Œ

**è·å– API Key:**
1. è®¿é—® [Together AI](https://api.together.xyz/)
2. æ³¨å†Œè´¦æˆ·
3. åœ¨è®¾ç½®é¡µé¢è·å– API Key

### 4. Anthropic Claude (é€šè¿‡ä»£ç†)

**é…ç½®ç¤ºä¾‹:**
- Base URL: `https://api.anthropic.com/v1` (éœ€è¦ä»£ç†è½¬æ¢)
- API Key: `sk-ant-...`
- Model Name: `claude-3-sonnet-20240229`

**æ³¨æ„:** Claude API æ ¼å¼ä¸ OpenAI ä¸åŒï¼Œéœ€è¦ä½¿ç”¨ä»£ç†æœåŠ¡è½¬æ¢ã€‚

### 5. æœ¬åœ° Ollama

**é…ç½®ç¤ºä¾‹:**
- Base URL: `http://localhost:11434/v1`
- API Key: `ollama` (ä»»æ„å€¼)
- Model Name: `llama2`, `codellama`, `mistral`

**å®‰è£… Ollama:**
```bash
# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.ai/install.sh | sh

# å¯åŠ¨æœåŠ¡
ollama serve

# ä¸‹è½½æ¨¡å‹
ollama pull llama2
```

**ç‰¹ç‚¹:**
- å®Œå…¨æœ¬åœ°è¿è¡Œ
- éšç§ä¿æŠ¤
- æ— ç½‘ç»œä¾èµ–
- å…è´¹ä½¿ç”¨

### 6. Azure OpenAI

**é…ç½®ç¤ºä¾‹:**
- Base URL: `https://{resource-name}.openai.azure.com/openai/deployments/{deployment-name}`
- API Key: `...`
- Model Name: `gpt-35-turbo`, `gpt-4`

**ç‰¹ç‚¹:**
- ä¼ä¸šçº§æœåŠ¡
- æ•°æ®éšç§ä¿æŠ¤
- ç¨³å®šæ€§é«˜

## ğŸ” API Key å®‰å…¨

### æœ€ä½³å®è·µ

1. **æ°¸è¿œä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç  API Key**
2. **ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨æ•æ„Ÿä¿¡æ¯**
3. **å®šæœŸè½®æ¢ API Key**
4. **é™åˆ¶ API Key æƒé™**
5. **ç›‘æ§ API ä½¿ç”¨æƒ…å†µ**

### æœ¬åœ°å­˜å‚¨

LiteFlow å°† API Key å­˜å‚¨åœ¨æµè§ˆå™¨çš„ `localStorage` ä¸­ï¼š

```javascript
// å­˜å‚¨é…ç½®
localStorage.setItem('llm-liteflow-storage', JSON.stringify({
  llmConfig: {
    baseUrl: 'https://api.openai.com/v1',
    apiKey: 'sk-...',
    modelName: 'gpt-3.5-turbo'
  }
}));

// è¯»å–é…ç½®
const config = JSON.parse(localStorage.getItem('llm-liteflow-storage'));
```

### å®‰å…¨æ³¨æ„äº‹é¡¹

- æ•°æ®ä»…å­˜å‚¨åœ¨æœ¬åœ°æµè§ˆå™¨
- ä¸ä¼šå‘é€åˆ°ä»»ä½•ç¬¬ä¸‰æ–¹æœåŠ¡å™¨
- æ¸…é™¤æµè§ˆå™¨æ•°æ®ä¼šåˆ é™¤é…ç½®
- å»ºè®®å®šæœŸå¤‡ä»½é‡è¦é…ç½®

## ğŸš¨ é”™è¯¯å¤„ç†

### å¸¸è§é”™è¯¯

#### 1. 401 Unauthorized
```json
{
  "error": {
    "message": "Invalid API key",
    "type": "invalid_request_error"
  }
}
```

**è§£å†³æ–¹æ¡ˆ:**
- æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®
- ç¡®è®¤ API Key æ˜¯å¦æœ‰æ•ˆ
- æ£€æŸ¥ API Key æƒé™

#### 2. 429 Rate Limit Exceeded
```json
{
  "error": {
    "message": "Rate limit exceeded",
    "type": "rate_limit_error"
  }
}
```

**è§£å†³æ–¹æ¡ˆ:**
- ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
- å‡çº§ API è®¡åˆ’
- å®ç°è¯·æ±‚é™æµ

#### 3. 404 Not Found
```json
{
  "error": {
    "message": "Model not found",
    "type": "invalid_request_error"
  }
}
```

**è§£å†³æ–¹æ¡ˆ:**
- æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®
- ç¡®è®¤æ¨¡å‹æ˜¯å¦å¯ç”¨
- æŸ¥çœ‹æœåŠ¡å•†æ–‡æ¡£

#### 4. CORS é”™è¯¯

**é”™è¯¯ä¿¡æ¯:**
```
Access to fetch at 'https://api.openai.com/v1/chat/completions' from origin 'http://localhost:5173' has been blocked by CORS policy
```

**è§£å†³æ–¹æ¡ˆ:**
- ä½¿ç”¨æ”¯æŒ CORS çš„ API æœåŠ¡
- é€šè¿‡ä»£ç†æœåŠ¡å™¨è½¬å‘è¯·æ±‚
- ä½¿ç”¨æµè§ˆå™¨æ‰©å±•ç¦ç”¨ CORS (ä»…å¼€å‘ç¯å¢ƒ)

## ğŸ”§ è‡ªå®šä¹‰ API é›†æˆ

### æ·»åŠ æ–°çš„ API æä¾›å•†

1. **ä¿®æ”¹æ‰§è¡Œå¼•æ“**

```javascript
// src/utils/executionEngine.js
async executeLlmNode(node) {
  // æ ¹æ® baseUrl åˆ¤æ–­æä¾›å•†ç±»å‹
  const provider = this.detectProvider(this.llmConfig.baseUrl);
  
  switch (provider) {
    case 'openai':
      return await this.executeOpenAIRequest(node);
    case 'anthropic':
      return await this.executeAnthropicRequest(node);
    case 'custom':
      return await this.executeCustomRequest(node);
    default:
      return await this.executeOpenAIRequest(node); // é»˜è®¤ä½¿ç”¨ OpenAI æ ¼å¼
  }
}
```

2. **å®ç°è‡ªå®šä¹‰è¯·æ±‚æ–¹æ³•**

```javascript
async executeCustomRequest(node) {
  const inputs = this.getNodeInputs(node.id);
  const prompt = inputs.join('\n');

  const response = await fetch(`${this.llmConfig.baseUrl}/custom/endpoint`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${this.llmConfig.apiKey}`,
    },
    body: JSON.stringify({
      // è‡ªå®šä¹‰è¯·æ±‚æ ¼å¼
      input: prompt,
      model: this.llmConfig.modelName,
      parameters: {
        temperature: 0.7
      }
    }),
  });

  const data = await response.json();
  // è§£æè‡ªå®šä¹‰å“åº”æ ¼å¼
  return data.output || data.result;
}
```

### ä»£ç†æœåŠ¡å™¨ç¤ºä¾‹

å¦‚æœéœ€è¦è§£å†³ CORS é—®é¢˜æˆ–è½¬æ¢ API æ ¼å¼ï¼Œå¯ä»¥åˆ›å»ºä»£ç†æœåŠ¡å™¨ï¼š

```javascript
// proxy-server.js
const express = require('express');
const cors = require('cors');
const app = express();

app.use(cors());
app.use(express.json());

app.post('/api/proxy', async (req, res) => {
  const { baseUrl, apiKey, ...requestData } = req.body;
  
  try {
    const response = await fetch(`${baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify(requestData),
    });
    
    const data = await response.json();
    res.json(data);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

app.listen(3001, () => {
  console.log('ä»£ç†æœåŠ¡å™¨è¿è¡Œåœ¨ http://localhost:3001');
});
```

## ğŸ“Š API ä½¿ç”¨ç›‘æ§

### è¯·æ±‚æ—¥å¿—

LiteFlow åœ¨å¼€å‘æ¨¡å¼ä¸‹ä¼šè®°å½• API è¯·æ±‚ï¼š

```javascript
console.log('API Request:', {
  url: `${baseUrl}/chat/completions`,
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: requestData
});

console.log('API Response:', {
  status: response.status,
  data: responseData
});
```

### æ€§èƒ½ç›‘æ§

```javascript
const startTime = performance.now();
const response = await fetch(apiUrl, options);
const endTime = performance.now();

console.log(`API è¯·æ±‚è€—æ—¶: ${endTime - startTime}ms`);
```

## ğŸ”„ API ç‰ˆæœ¬å…¼å®¹æ€§

### OpenAI API ç‰ˆæœ¬

- **v1**: å½“å‰ç¨³å®šç‰ˆæœ¬
- **Legacy**: æ—§ç‰ˆæœ¬ (ä¸æ¨è)

### æ¨¡å‹ç‰ˆæœ¬ç®¡ç†

```javascript
const modelVersions = {
  'gpt-3.5-turbo': 'gpt-3.5-turbo-0125',
  'gpt-4': 'gpt-4-0613',
  'gpt-4-turbo': 'gpt-4-turbo-2024-04-09'
};
```

## ğŸ“š å‚è€ƒèµ„æº

- [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs/api-reference)
- [Groq API æ–‡æ¡£](https://console.groq.com/docs)
- [Together AI æ–‡æ¡£](https://docs.together.ai/)
- [Ollama API æ–‡æ¡£](https://github.com/ollama/ollama/blob/main/docs/api.md)
- [Anthropic API æ–‡æ¡£](https://docs.anthropic.com/claude/reference)

## ğŸ†˜ è·å–å¸®åŠ©

å¦‚æœé‡åˆ° API ç›¸å…³é—®é¢˜ï¼š

1. æ£€æŸ¥ API Key å’Œé…ç½®
2. æŸ¥çœ‹æµè§ˆå™¨æ§åˆ¶å°é”™è¯¯ä¿¡æ¯
3. å‚è€ƒæœåŠ¡å•†å®˜æ–¹æ–‡æ¡£
4. åœ¨é¡¹ç›® Issues ä¸­æœç´¢ç›¸å…³é—®é¢˜
5. åˆ›å»ºæ–°çš„ Issue æè¿°é—®é¢˜

